{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "7489139fadedff3b08012098ca2abd2058b255578d7205af55c55f231e9a91e1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Libraries\n",
    "################################################################################\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocesamiento\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks, CondensedNearestNeighbour\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Load data\n",
    "################################################################################\n",
    "\n",
    "original_train = pd.read_csv(\"data/train_values.csv\")\n",
    "original_test  = pd.read_csv(\"data/test_values.csv\")\n",
    "original_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "train  = original_train\n",
    "test   = original_test\n",
    "labels = original_labels\n",
    "\n",
    "# Columnas\n",
    "for i,c in enumerate(train.columns):\n",
    "    print(i, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# No hay duplicados en los ids, se pueden quitar\n",
    "############################################################################\n",
    "\n",
    "train = train.drop(columns=\"building_id\")\n",
    "test = test.drop(columns=\"building_id\")\n",
    "labels = labels.drop(columns=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Preprocesado Nº 2\n",
    "# Quitar columnnas innecesarias / no interesantes\n",
    "############################################################################\n",
    "\n",
    "# Quitamos geo_2 y geo_3. Tienen demasiadas categorías diferentes para los árboles,\n",
    "# y no se solapan\n",
    "train = train.drop(columns=[\"geo_level_2_id\",\"geo_level_3_id\"])\n",
    "test = test.drop(columns=[\"geo_level_2_id\",\"geo_level_3_id\"])\n",
    "\n",
    "\n",
    "# En estas dos predomina (+85%) una clase y el resto no sirve para determinar\n",
    "# ninguna etiqueta (se mantiene la proporción o las 3 están representadas)\n",
    "train = train.drop(columns=[\"plan_configuration\",\"legal_ownership_status\"])\n",
    "test = test.drop(columns=[\"plan_configuration\",\"legal_ownership_status\"])\n",
    "\n",
    "# Altura y nº de plantas altamente correladas, categorizamos nº de plantas y quitamos altura\n",
    "# Solo una instancia con 9 plantas, y las anteriores no siguen el mismo patrón (que todas sufrieran el mismo tipo de daño)\n",
    "# Como tenemos proporciones muy similares, juntamos las +5 con ella\n",
    "train[\"count_floors_pre_eq\"] = train[\"count_floors_pre_eq\"].replace({6:5, 7:5, 8:5, 9:5})\n",
    "test[\"count_floors_pre_eq\"] = test[\"count_floors_pre_eq\"].replace({6:5, 7:5, 8:5, 9:5})\n",
    "\n",
    "# No nos interesan variables numéricas en los árboles, acabarían discretizándose\n",
    "train = train.drop(columns=[\"height_percentage\"])\n",
    "test = test.drop(columns=[\"height_percentage\"])\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# v10 - Discretizar variables numéricas (age, area_percentage)\n",
    "# count_families y count_floors considerarlas como categóricas\n",
    "# Al final son age y area_percentage\n",
    "# Age tiene años de 5 en 5 desde 0 hasta 200, más luego uno de 995, se podrían agrupar en 20\n",
    "# Area percentage son porcentajes, se podría agrupar en intervalos de 10\n",
    "# Los boxplot nos muestra una alta concentración en la parte baja con un gran\n",
    "# número de puntos dispersos hacia arriba, se ve apropiado agruparlo mediante\n",
    "# un método kmeans de manera que los puntos se asocien a una partición según\n",
    "# el centroide más cercano\n",
    "# \n",
    "# Los\n",
    "############################################################################\n",
    "\n",
    "disc = KBinsDiscretizer(n_bins=15, encode='ordinal', strategy='kmeans')\n",
    "age = disc.fit_transform(train[[\"age\"]])\n",
    "age = pd.DataFrame(age)\n",
    "\n",
    "test.age = pd.DataFrame(disc.transform(test[[\"age\"]]))\n",
    "\n",
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='kmeans')\n",
    "area = disc.fit_transform(train[[\"area_percentage\"]])\n",
    "area = pd.DataFrame(area)\n",
    "\n",
    "test.area_percentage = pd.DataFrame(disc.transform(test[[\"area_percentage\"]]))\n",
    "\n",
    "age.hist()\n",
    "area.hist()\n",
    "\n",
    "train.age = age\n",
    "train.area_percentage = area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Eliminar instancias duplicadas\n",
    "############################################################################\n",
    "\n",
    "df = train.join(labels[\"damage_grade\"])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "train = df.drop(columns=[\"damage_grade\"])\n",
    "labels = df[\"damage_grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# One-hot-enconding\n",
    "############################################################################\n",
    "\n",
    "label_encoders = {}\n",
    "# categorical_columns = [\"geo_level_1_id\",\n",
    "#                         \"land_surface_condition\",\n",
    "#                         \"foundation_type\",\n",
    "#                         \"roof_type\",\n",
    "#                         \"ground_floor_type\",\n",
    "#                         \"other_floor_type\",\n",
    "#                         \"position\",\n",
    "#                        ]\n",
    "\n",
    "# All\n",
    "categorical_columns = train.columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    # Para training\n",
    "    dummies = pd.get_dummies(train[column])\n",
    "    dummies.columns = [column + \"_\" + str(x) for x in dummies.columns]\n",
    "    train = train.drop(columns=column)\n",
    "    train = pd.concat([train, dummies], axis=1)\n",
    "\n",
    "    # Para test\n",
    "    dummies = pd.get_dummies(test[column])\n",
    "    dummies.columns = [column + \"_\" + str(x) for x in dummies.columns]\n",
    "    test = test.drop(columns=column)\n",
    "    test = pd.concat([test, dummies], axis=1)\n",
    "\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in enumerate(train.columns):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# v7 - SMOTE + ENN\n",
    "# Oversampling de todas las clases inferiores, undersampling de puntos ruidosos\n",
    "############################################################################\n",
    "\n",
    "sme = SMOTEENN(random_state=42)\n",
    "print('Original dataset shape %s' % len(labels))\n",
    "X_res, y_res = sme.fit_resample(train, labels)\n",
    "print('Resampled dataset shape %s' % len(y_res))\n",
    "\n",
    "train = pd.DataFrame(X_res)\n",
    "labels = pd.DataFrame(y_res)\n",
    "\n",
    "labels.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# v8y9 - SMOTE\n",
    "############################################################################\n",
    "\n",
    "# v8 Con onehot\n",
    "# categorical = list(range(0,len(train.columns)))\n",
    "# categorical.remove(14)\n",
    "# categorical = categorical[3:]\n",
    "\n",
    "# v9 SIN ONEHOT\n",
    "categorical = list(range(0,len(train.columns)))\n",
    "categorical.remove(1)\n",
    "categorical.remove(2)\n",
    "categorical.remove(3)\n",
    "categorical.remove(21)\n",
    "\n",
    "sm_nc = SMOTENC(categorical_features=categorical, random_state=0)\n",
    "print('Original dataset shape %s' % len(labels))\n",
    "x_smnc, y_smnc = sm_nc.fit_resample(train, labels)\n",
    "print('Resampled dataset shape %s' % len(y_smnc))\n",
    "\n",
    "train = pd.DataFrame(x_smnc)\n",
    "labels = pd.DataFrame(y_smnc)\n",
    "\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Preprocesado 3.1\n",
    "# Selección de características\n",
    "# For classification: chi2, f_classif, mutual_info_classif\n",
    "############################################################################\n",
    "\n",
    "# selector = SelectKBest(chi2, k=15)\n",
    "selector = SelectKBest(mutual_info_classif, k=80)\n",
    "selector.fit(train, labels)\n",
    "x_reduced = selector.transform(train)\n",
    "\n",
    "# Ver columnas\n",
    "columns = train.columns[selector.get_support()]\n",
    "print(columns)\n",
    "\n",
    "# test['count_families_9'] = 0\n",
    "\n",
    "# Select same feautures as with train\n",
    "tst_reduced = selector.transform(test)\n",
    "test = pd.DataFrame(tst_reduced, columns=columns)\n",
    "train = pd.DataFrame(x_reduced, columns=columns)\n",
    "\n",
    "# Mostrar scores\n",
    "# pd.DataFrame(selector.scores_).transpose()\n",
    "plt.bar([i for i in range(len(selector.scores_))], selector.scores_)\n",
    "plt.show()\n",
    "\n",
    "x_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Preprocesado 3.1 ... continuación\n",
    "# Aplicar undersampling\n",
    "############################################################################\n",
    "\n",
    "# undersample = TomekLinks()\n",
    "# undersample = CondensedNearestNeighbour(n_neighbors=3)\n",
    "undersample = EditedNearestNeighbours(n_neighbors=3)\n",
    "\n",
    "# transform the dataset\n",
    "X, y = undersample.fit_resample(train, labels)\n",
    "\n",
    "print(\"Antes: \" + str(len(train)))\n",
    "print(\"Después: \" + str(len(X)))\n",
    "\n",
    "train = pd.DataFrame(X, columns=train.columns)\n",
    "labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# v1 Juntar columnas binarias\n",
    "################################################################################\n",
    "\n",
    "# Join has_superstructure (binary) columns has strings\n",
    "# Get selected rows to string\n",
    "df = train.iloc[:,15:25].astype(str)\n",
    "df_test = test.iloc[:,15:25].astype(str)\n",
    "\n",
    "# Join them\n",
    "train[\"has_superstructure\"] = df.apply(lambda x: ''.join(x), axis=1)\n",
    "test[\"has_superstructure\"] = df_test.apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "# Join has_secondary (binary) columns has strings\n",
    "# Get selected rows to string\n",
    "df = train.iloc[:,29:38].astype(str)\n",
    "df_test = test.iloc[:,29:38].astype(str)\n",
    "\n",
    "# Join them\n",
    "train[\"has_secondary\"] = df.apply(lambda x: ''.join(x), axis=1)\n",
    "test[\"has_secondary\"] = df_test.apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "# Remove joined columns\n",
    "removed_cols = list(range(15,26)) + list(range(29,39))\n",
    "train = train.drop(columns=train.columns[removed_cols])\n",
    "test = test.drop(columns=test.columns[removed_cols])\n",
    "\n",
    "# Convert new cols to int\n",
    "# train[\"has_superstructure\"] = train[\"has_superstructure\"].apply(lambda x: int(x,2))\n",
    "# train[\"has_secondary\"] = train[\"has_secondary\"].apply(lambda x: int(x,2))\n",
    "# train\n",
    "\n",
    "# Convert to categorical in order\n",
    "# train.has_secondary = train.has_secondary.astype(\"category\").cat.codes\n",
    "# train.has_superstructure = train.has_superstructure.astype('category').cat.codes\n",
    "\n",
    "# has_secondary_use is enconded in has_secondary, remove it\n",
    "train = train.drop(columns=\"has_secondary_use\")\n",
    "test = test.drop(columns=\"has_secondary_use\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "source": [
    "################################################################################\n",
    "# Write data\n",
    "################################################################################\n",
    "train.to_csv(\"data/v12 - preprocessed_train.csv\", index=False)\n",
    "labels.to_csv(\"data/v12 - preprocessed_train_labels.csv\", index=False)\n",
    "test.to_csv(\"data/v12 - preprocessed_test.csv\", index=False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}